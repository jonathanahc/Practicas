{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathanahc/Practicas/blob/main/Pr%C3%A1ctica_26_Regresion_Ridge_y_Lasso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Instrucciones y Objetivos para la PrÃ¡ctica: RegresiÃ³n Lasso y Ridge**\n",
        "\n",
        "#### **ðŸ“Œ Objetivos de la PrÃ¡ctica:**  \n",
        "Al finalizar esta prÃ¡ctica, los estudiantes serÃ¡n capaces de:  \n",
        "1. **Realizar un AnÃ¡lisis Exploratorio de Datos (EDA)** completo, incluyendo visualizaciÃ³n de distribuciones, detecciÃ³n de outliers y anÃ¡lisis de correlaciones.  \n",
        "2. **Preprocesar datos** correctamente, manejando valores faltantes, codificando variables categÃ³ricas y escalando caracterÃ­sticas.  \n",
        "3. **Implementar modelos de regresiÃ³n Lasso y Ridge**, entendiendo cÃ³mo la regularizaciÃ³n afecta los coeficientes.  \n",
        "4. **Verificar los supuestos de la regresiÃ³n lineal** (linealidad, normalidad de residuos, homocedasticidad y multicolinealidad).  \n",
        "5. **Comparar el rendimiento** de ambos modelos y analizar quÃ© variables son mÃ¡s relevantes en cada caso.  \n",
        "\n",
        "---\n",
        "\n",
        "### **ðŸ“‹ Instrucciones**  \n",
        "\n",
        "#### **ðŸ”¹ Paso 1: ConfiguraciÃ³n Inicial**\n",
        "âœ… Carga el set de datos que puedes encontrar en el campus virtual\n",
        "âœ… Ejecutar las celdas de importaciÃ³n de librerÃ­as y carga del dataset.  \n",
        "âœ… Familiarizarse con los datos usando `.head()`, `.info()` y `.describe()`.  \n",
        "\n",
        "#### **ðŸ”¹ Paso 2: AnÃ¡lisis Exploratorio (EDA)**  \n",
        "ðŸ“Š **Para variables numÃ©ricas:**  \n",
        "- Generar histogramas y boxplots para identificar distribuciones y outliers.  \n",
        "- Calcular medidas de tendencia central y dispersiÃ³n.  \n",
        "\n",
        "ðŸ“Š **Para variables categÃ³ricas:**  \n",
        "- Usar grÃ¡ficos de barras para visualizar frecuencias.    \n",
        "\n",
        "#### **ðŸ”¹ Paso 3: Matriz de CorrelaciÃ³n**  \n",
        "âœ… Calcular la matriz de correlaciÃ³n **solo para variables numÃ©ricas**.  \n",
        "âœ… Generar un **mapa de calor** para visualizar relaciones.  \n",
        "ðŸ“Œ **Pregunta:** Â¿QuÃ© variables estÃ¡n mÃ¡s correlacionadas con el target (`charges`)?  \n",
        "\n",
        "#### **ðŸ”¹ Paso 4: Preprocesamiento**  \n",
        "ðŸ”§ **Tareas:**  \n",
        "1. Manejar valores faltantes con `SimpleImputer`.  \n",
        "2. Codificar variables categÃ³ricas con `OneHotEncoder`.  \n",
        "3. Estandarizar variables numÃ©ricas con `StandardScaler`.  \n",
        "âœ… Verificar que el dataset transformado no tenga valores nulos.  \n",
        "\n",
        "#### **ðŸ”¹ Paso 5: Modelado (Lasso y Ridge)**  \n",
        "ðŸŽ¯ **Para cada modelo:**  \n",
        "1. Ajustar el modelo con los hiperparÃ¡metros dados (`alpha=0.1` para Lasso, `alpha=1.0` para Ridge).  \n",
        "2. Calcular **MSE** y **RÂ²** para evaluar rendimiento.  \n",
        "3. Analizar los coeficientes para identificar variables importantes.  \n",
        "\n",
        "ðŸ“Œ **Pregunta:**  \n",
        "- Â¿QuÃ© modelo tiene un mejor RÂ²? Â¿Por quÃ© crees que ocurre esto?  \n",
        "- Â¿QuÃ© variables tienen coeficientes cercanos a cero en Lasso? Â¿Por quÃ©?  \n",
        "\n",
        "#### **ðŸ”¹ Paso 6: VerificaciÃ³n de Supuestos**  \n",
        "ðŸ“‰ **Para cada modelo, verificar:**  \n",
        "1. **Linealidad** (grÃ¡fico de residuos vs predicciones).  \n",
        "2. **Normalidad de residuos** (QQ-Plot y test de Shapiro-Wilk).  \n",
        "3. **Homocedasticidad** (test de Breusch-Pagan).  \n",
        "4. **Multicolinealidad** (VIF > 10 indica problema).  \n",
        "\n",
        "ðŸ“Œ **Pregunta:**  \n",
        "- Â¿Se cumplen los supuestos en ambos modelos?  \n",
        "- Si hay heterocedasticidad, Â¿cÃ³mo podrÃ­a solucionarse?  \n",
        "\n",
        "#### **ðŸ”¹ Paso 7: ComparaciÃ³n Final**  \n",
        "ðŸ“Š **Analizar:**  \n",
        "- Â¿QuÃ© modelo es mÃ¡s interpretable?  \n",
        "- Â¿CuÃ¡l reduce mejor el sobreajuste?  \n",
        "- Â¿QuÃ© variables son mÃ¡s importantes en cada caso?  \n",
        "\n",
        "---\n",
        "\n",
        "### **ðŸ“Œ Entrega de la PrÃ¡ctica**  \n",
        "Al finalizar la practica, incluye un texto con los siguientes elementos\n",
        "- Incluir **comentarios explicativos** en cada paso.  \n",
        "- Responder las **preguntas planteadas** en celdas Markdown.  \n",
        "\n",
        "ðŸŽ¯ **Criterios de EvaluaciÃ³n:**  \n",
        "âœ” **Correcto preprocesamiento** (manejo de nulos, escalado, encoding).  \n",
        "âœ” **AnÃ¡lisis visual y estadÃ­stico** (grÃ¡ficos claros, interpretaciÃ³n de resultados).  \n",
        "âœ” **ValidaciÃ³n de supuestos** (justificaciÃ³n de si se cumplen o no).  \n",
        "âœ” **ComparaciÃ³n crÃ­tica** entre Lasso y Ridge.  "
      ],
      "metadata": {
        "id": "cutGS1pjlfr3"
      }
    }
  ]
}